{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('listings_unitedstates_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.columns[[0]], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing punctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Replacing the punctuations with no space, which in effect deletes the punctuation marks \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    # Return the text stripped of punctuation marks\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Description'] = data['Description'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Customer’s mission is to create groundbreaking sport innovations by making their products more sustainable building a creative and diverse global team and making a positive impact in communities where we live and work Their purpose is to bring inspiration and innovation to unite the world through sport to create a healthy planet active communities and an equal playing field for all  We are seeking an experienced Data Scientist on a contract basis to join our Customer’s Supply Chain organization  What you’ll do  Uses advanced mathematical and statistical concepts and theories to analyze and collect data and construct solutions to business problems Performs complex statistical analysis on experimental or business data to validate and quantify trends or patterns identified by business analysts Constructs predictive models algorithms and probability engines to support data analysis or product functions verifies model and algorithm effectiveness based on realworld results Integrates statistical mathematical predictive modeling and business analysis skills to manage and manipulate complex highvolume data from a variety of sources Analyzes large quantities of data and presents insights and predictions eg on customer behaviors and preferences new products and services to support management planning execution and monitoring of business decisions  The ideal candidate will have  Advanced mathematical skills Exceptional analytical and conceptual thinking skills Experience working in a collaborative team environment Strong written and verbal communication skills  Education Bachelor’s Degree  Hours  Location MF 40 hoursweek This role will be remote while COVID restrictions are in place The expectation is to be onsite at our Customer’s Beaverton OR location once it is deemed safe to do so  Now for the Perks  Health Benefits Medical Dental Vision Life including spouse  child 401k STDLTD ADD and Commuter Benefits program'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Description'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = (\" \".join(data['Description'].tolist())).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = nltk.word_tokenize(corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "\n",
    "A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = [\"analysis\",\"data\",\"science\",\"complex\",\"environment\",\n",
    "                     \"preferred\",\"qualifications\",\"required\",\"development\",\"design\",\n",
    "                     \"relevant\",\"develop\",\"tools\",\"including\",\"ability\",\"business\",\n",
    "                     \"scientist\",\"quantitative\",\"related\",'’', 'analytics', 'new', 'year',\n",
    "                    'solution', 'technology', 'working', 'strong', 'using', 'problem',\n",
    "                    'role', 'us', 'company', 'modeling', 'help']\n",
    "\n",
    "for w in custom_stop_words:\n",
    "    if w not in stop:\n",
    "        stop.append(w)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_no_stopword = [word.lower() for word in tokenized_corpus if word.lower() not in stop]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "Lemmatization tries to achieve a similar base “stem” for a word. However, what makes it different is that it finds the dictionary word instead of truncating the original word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_tokens = [lmtzr.lemmatize(token) for token in tokens_no_stopword]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(lemmatized_tokens)\n",
    "\n",
    "# get the top words\n",
    "top_words = []\n",
    "for key, value in fd.items():\n",
    "    top_words.append((key, value))\n",
    "\n",
    "# sort the list by the top frequencies\n",
    "top_words = sorted(top_words, key = lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('experience', 4684),\n",
       " ('team', 3015),\n",
       " ('work', 2571),\n",
       " ('learning', 2244),\n",
       " ('model', 1875),\n",
       " ('machine', 1697),\n",
       " ('product', 1671),\n",
       " ('skill', 1669),\n",
       " ('year', 1308),\n",
       " ('solution', 1268),\n",
       " ('opportunity', 1258),\n",
       " ('customer', 1213),\n",
       " ('statistical', 1167),\n",
       " ('research', 1061),\n",
       " ('engineering', 1009),\n",
       " ('support', 963),\n",
       " ('knowledge', 957),\n",
       " ('project', 943),\n",
       " ('technique', 939),\n",
       " ('python', 931)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_20 = top_words[:20]\n",
    "top_words_20 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
